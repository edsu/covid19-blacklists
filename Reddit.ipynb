{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit\n",
    "\n",
    "Reddit [supposedly](https://thenextweb.com/contributors/2018/04/19/reddit-now-active-users-twitter-engaging-porn/) has more active users than Twitter. But who are those users and what are the users doing? One indicator of that is the [Coronavirus Subreddit](https://www.reddit.com/r/Coronavirus/) which has 1.9 million members. We can use the PushShift API to see how the DomainTools domains are being shared and interacted with. Reddit is primarily a social bookmarking site where people can share links to things and have conversations about them. [PushShift's API](https://github.com/pushshift/api) lets you search for submissions that include links to a particular domain.\n",
    "\n",
    "For example to search for the nytimes.com domain:\n",
    "\n",
    "    http://api.pushshift.io/reddit/submission/search?domain=nytimes.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_awardings': [],\n",
       " 'allow_live_comments': False,\n",
       " 'author': 'demonbadger',\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_a6y3w',\n",
       " 'author_patreon_flair': False,\n",
       " 'author_premium': False,\n",
       " 'awarders': [],\n",
       " 'can_mod_post': False,\n",
       " 'contest_mode': False,\n",
       " 'created_utc': 1586263598,\n",
       " 'domain': 'nytimes.com',\n",
       " 'full_link': 'https://www.reddit.com/r/Idaho/comments/fwjwar/a_liberty_rebellion_in_idaho_threatens_to/',\n",
       " 'gildings': {},\n",
       " 'id': 'fwjwar',\n",
       " 'is_crosspostable': True,\n",
       " 'is_meta': False,\n",
       " 'is_original_content': False,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_robot_indexable': True,\n",
       " 'is_self': False,\n",
       " 'is_video': False,\n",
       " 'link_flair_background_color': '',\n",
       " 'link_flair_richtext': [],\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'link_flair_type': 'text',\n",
       " 'locked': False,\n",
       " 'media_only': False,\n",
       " 'no_follow': True,\n",
       " 'num_comments': 1,\n",
       " 'num_crossposts': 0,\n",
       " 'over_18': False,\n",
       " 'permalink': '/r/Idaho/comments/fwjwar/a_liberty_rebellion_in_idaho_threatens_to/',\n",
       " 'pinned': False,\n",
       " 'post_hint': 'link',\n",
       " 'preview': {'enabled': False,\n",
       "  'images': [{'id': 's-2FiHZ8M4-dXc_YkRoFeGHBajLfo-SFgcRHp-c5d6s',\n",
       "    'resolutions': [{'height': 56,\n",
       "      'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0ef592a9585e6a9ff50e4f1609694af1cf9d844f',\n",
       "      'width': 108},\n",
       "     {'height': 113,\n",
       "      'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a8f1d576fc4ae0d9d5aa505024fe41a64eef50d',\n",
       "      'width': 216},\n",
       "     {'height': 167,\n",
       "      'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b412fde675aa52dfc43825a15bdf8eea10d39cdd',\n",
       "      'width': 320},\n",
       "     {'height': 335,\n",
       "      'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0684e2524a06538fdd1875f6b499a43d260cebb1',\n",
       "      'width': 640},\n",
       "     {'height': 502,\n",
       "      'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c7f8e93f277195340dac67fd061a61cf39704f9b',\n",
       "      'width': 960}],\n",
       "    'source': {'height': 550,\n",
       "     'url': 'https://external-preview.redd.it/1XfTGTZZYaEL8NJ3wlKjLt6u4st4qYbLMF28BT2RW7w.jpg?auto=webp&amp;s=7ffa34a109aedf2e0cfea9e3baa16fe6e28fab6f',\n",
       "     'width': 1050},\n",
       "    'variants': {}}]},\n",
       " 'retrieved_on': 1586263600,\n",
       " 'score': 1,\n",
       " 'selftext': '',\n",
       " 'send_replies': True,\n",
       " 'spoiler': False,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'Idaho',\n",
       " 'subreddit_id': 't5_2qtxr',\n",
       " 'subreddit_subscribers': 11534,\n",
       " 'subreddit_type': 'public',\n",
       " 'thumbnail': 'https://b.thumbs.redditmedia.com/5RDhuayK5a2iAfz4L4lkciI3J5vFcLQaiA_tU-Z2gmA.jpg',\n",
       " 'thumbnail_height': 73,\n",
       " 'thumbnail_width': 140,\n",
       " 'title': 'A ‘Liberty’ Rebellion in Idaho Threatens to Undermine Coronavirus Orders - The New York Times',\n",
       " 'total_awards_received': 0,\n",
       " 'treatment_tags': [],\n",
       " 'url': 'https://www.nytimes.com/2020/04/07/us/coronavirus-idaho-bundy-patriot.html'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://api.pushshift.io/reddit/submission/search?domain=nytimes.com\"\n",
    "results = requests.get(url).json()['data']\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get *a lot* of information back, but some key bits that will be useful for us are:\n",
    "\n",
    "* **title:** A ‘Liberty’ Rebellion in Idaho Threatens to Undermine Coronavirus Orders - The New York Times'\n",
    "* **url:** The URL for the nytimes.com post\n",
    "* **author:** the user who sent the post\n",
    "* **comments:** the number of comments the post received\n",
    "* **score:** the number of upvotes the post received \n",
    "* **created_utc:** the date the post was created\n",
    "* **id**: Reddit's unique identifier for the post\n",
    "\n",
    "## Collect the Data\n",
    "\n",
    "So we're ready to look at DomainTools data. Before we do that it's worth pointint out that we can only get up to 1000 posts at a time. While it's certainly possible to have more than 1000 posts for the *nytimes.com* domain, I'm thinking that we won't see more than this for the DomainTools domains. But it will be useful to print out a message if we do. So we will get back at most 1000 results at a time, and order them by their *score* using these API parameters:\n",
    "\n",
    "* **limit:** the maximum number of results to return (no higher than 1000) \n",
    "* **sort_type:** we can use this to order results by their score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that looks up the data for a given domain and returns it. The only small thing we do here is convert the `created_utc` value to a formatted datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def reddit_posts(domain):\n",
    "    url = \"http://api.pushshift.io/reddit/submission/search\"\n",
    "    params = {\"domain\": domain, \"limit\": 1000, \"sort_type\": \"score\"}\n",
    "    resp = requests.get(url, params=params)\n",
    "    if resp.status_code != 200:\n",
    "        print(resp)\n",
    "    results = resp.json()['data']\n",
    "    for result in results:\n",
    "        result['created'] = datetime.datetime.fromtimestamp(result['created_utc']).isoformat()\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll need the DomainTools data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('data/domaintools/2020-04-06.csv.gz',\n",
    "    parse_dates=['created'], \n",
    "    sep='\\t',\n",
    "    names=['domain', 'created', 'risk']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write out the data as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "csv_path = 'data/reddit/{}.csv'.format(today)\n",
    "cols=['id', 'created', 'url', 'title', 'author', 'comments', 'score', 'domain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we're ready to start. But first lets limit to the riskiest domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91644"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riskiest = df[df.risk >= 99.0]\n",
    "len(riskiest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pause for 1 second between requests to PushShift's API just to be nice. It should take us no shorter than this many hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.456666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(riskiest) / 60 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We better get started then! The DictWriter class lets us define which columns to include in our output, and ignore ones that we are not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "cols = ['id', 'created', 'author', 'title', 'url', 'domain', 'score', 'comments']\n",
    "\n",
    "with open(csv_path, 'w') as fh:\n",
    "    out = csv.DictWriter(fh, fieldnames=cols, extrasaction='ignore')\n",
    "    for domain in riskiest.domain:\n",
    "        for post in reddit_posts(domain):\n",
    "            out.writerow(post)\n",
    "            sys.stdout.write('+')\n",
    "        time.sleep(1)\n",
    "        sys.stdout.write('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
